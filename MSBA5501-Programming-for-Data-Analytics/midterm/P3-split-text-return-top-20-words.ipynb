{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb69942",
   "metadata": {},
   "source": [
    "### Problem 3 (10 point) \n",
    "\n",
    "1. The last section of Steve Job's Stanford 2005 Graduation Address is given.\n",
    "\n",
    "2. Write code that would split the text into word list in lower case word list.    \n",
    "\n",
    "3. Write code to remove stop words, and then count the words.  \n",
    "\n",
    "4. Print the top 20 words by count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91f84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "steve_job = \"When I was young, there was an amazing publication called The Whole Earth Catalog, \\\n",
    "which was one of the bibles of my generation. It was created by a fellow named Stewart Brand not \\\n",
    "far from here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960s, \\\n",
    "before personal computers and desktop publishing, so it was all made with typewriters, \\\n",
    "scissors and Polaroid cameras. It was sort of like Google in paperback form, 35 years before Google \\\n",
    "came along: It was idealistic, and overflowing with neat tools and great notions.  Stewart and his team \\\n",
    "put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a \\\n",
    "final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a \\\n",
    "photograph of an early morning country road, the kind you might find yourself hitchhiking on if you \\\n",
    "were so adventurous. Beneath it were the words: Stay Hungry. Stay Foolish. It was their farewell \\\n",
    "message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And \\\n",
    "now, as you graduate to begin anew, I wish that for you.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89faf69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = {\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\",\\\n",
    "             \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \\\n",
    "             \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \\\n",
    "             \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \\\n",
    "             \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \\\n",
    "             \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \\\n",
    "             \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \\\n",
    "             \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \\\n",
    "             \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \\\n",
    "             \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \\\n",
    "             \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \\\n",
    "             \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \\\n",
    "             \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \\\n",
    "             \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \\\n",
    "             \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \\\n",
    "             \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \\\n",
    "             \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \\\n",
    "             \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \\\n",
    "             \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \\\n",
    "             \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \\\n",
    "             \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \\\n",
    "             \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \\\n",
    "             \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\\\n",
    "             \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \\\n",
    "             \"thereupon\", \"these\", \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \\\n",
    "             \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\\\n",
    "             \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \\\n",
    "             \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \\\n",
    "             \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\\\n",
    "             \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \\\n",
    "             \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396e8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to split the string into a list of words\n",
    "import re\n",
    "# place into list and lower case\n",
    "def process(text):\n",
    "    allwords = []\n",
    "    allwords.extend(re.split(\"\\,|\\s|\\?|\\&|\\\"|\\-\",text.strip().lower().replace(\".\",\"\")))\n",
    "    return allwords  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e99077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when',\n",
       " 'i',\n",
       " 'was',\n",
       " 'young',\n",
       " '',\n",
       " 'there',\n",
       " 'was',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'publication',\n",
       " 'called',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'earth',\n",
       " 'catalog',\n",
       " '',\n",
       " 'which',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bibles',\n",
       " 'of',\n",
       " 'my',\n",
       " 'generation',\n",
       " 'it',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'a',\n",
       " 'fellow',\n",
       " 'named',\n",
       " 'stewart',\n",
       " 'brand',\n",
       " 'not',\n",
       " 'far',\n",
       " 'from',\n",
       " 'here',\n",
       " 'in',\n",
       " 'menlo',\n",
       " 'park',\n",
       " '',\n",
       " 'and',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'it',\n",
       " 'to',\n",
       " 'life',\n",
       " 'with',\n",
       " 'his',\n",
       " 'poetic',\n",
       " 'touch',\n",
       " 'this',\n",
       " 'was',\n",
       " 'in',\n",
       " 'the',\n",
       " 'late',\n",
       " '1960s',\n",
       " '',\n",
       " 'before',\n",
       " 'personal',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'desktop',\n",
       " 'publishing',\n",
       " '',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'all',\n",
       " 'made',\n",
       " 'with',\n",
       " 'typewriters',\n",
       " '',\n",
       " 'scissors',\n",
       " 'and',\n",
       " 'polaroid',\n",
       " 'cameras',\n",
       " 'it',\n",
       " 'was',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'like',\n",
       " 'google',\n",
       " 'in',\n",
       " 'paperback',\n",
       " 'form',\n",
       " '',\n",
       " '35',\n",
       " 'years',\n",
       " 'before',\n",
       " 'google',\n",
       " 'came',\n",
       " 'along:',\n",
       " 'it',\n",
       " 'was',\n",
       " 'idealistic',\n",
       " '',\n",
       " 'and',\n",
       " 'overflowing',\n",
       " 'with',\n",
       " 'neat',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'great',\n",
       " 'notions',\n",
       " '',\n",
       " 'stewart',\n",
       " 'and',\n",
       " 'his',\n",
       " 'team',\n",
       " 'put',\n",
       " 'out',\n",
       " 'several',\n",
       " 'issues',\n",
       " 'of',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'earth',\n",
       " 'catalog',\n",
       " '',\n",
       " 'and',\n",
       " 'then',\n",
       " 'when',\n",
       " 'it',\n",
       " 'had',\n",
       " 'run',\n",
       " 'its',\n",
       " 'course',\n",
       " '',\n",
       " 'they',\n",
       " 'put',\n",
       " 'out',\n",
       " 'a',\n",
       " 'final',\n",
       " 'issue',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'mid',\n",
       " '1970s',\n",
       " '',\n",
       " 'and',\n",
       " 'i',\n",
       " 'was',\n",
       " 'your',\n",
       " 'age',\n",
       " 'on',\n",
       " 'the',\n",
       " 'back',\n",
       " 'cover',\n",
       " 'of',\n",
       " 'their',\n",
       " 'final',\n",
       " 'issue',\n",
       " 'was',\n",
       " 'a',\n",
       " 'photograph',\n",
       " 'of',\n",
       " 'an',\n",
       " 'early',\n",
       " 'morning',\n",
       " 'country',\n",
       " 'road',\n",
       " '',\n",
       " 'the',\n",
       " 'kind',\n",
       " 'you',\n",
       " 'might',\n",
       " 'find',\n",
       " 'yourself',\n",
       " 'hitchhiking',\n",
       " 'on',\n",
       " 'if',\n",
       " 'you',\n",
       " 'were',\n",
       " 'so',\n",
       " 'adventurous',\n",
       " 'beneath',\n",
       " 'it',\n",
       " 'were',\n",
       " 'the',\n",
       " 'words:',\n",
       " 'stay',\n",
       " 'hungry',\n",
       " 'stay',\n",
       " 'foolish',\n",
       " 'it',\n",
       " 'was',\n",
       " 'their',\n",
       " 'farewell',\n",
       " 'message',\n",
       " 'as',\n",
       " 'they',\n",
       " 'signed',\n",
       " 'off',\n",
       " 'stay',\n",
       " 'hungry',\n",
       " 'stay',\n",
       " 'foolish',\n",
       " 'and',\n",
       " 'i',\n",
       " 'have',\n",
       " 'always',\n",
       " 'wished',\n",
       " 'that',\n",
       " 'for',\n",
       " 'myself',\n",
       " 'and',\n",
       " 'now',\n",
       " '',\n",
       " 'as',\n",
       " 'you',\n",
       " 'graduate',\n",
       " 'to',\n",
       " 'begin',\n",
       " 'anew',\n",
       " '',\n",
       " 'i',\n",
       " 'wish',\n",
       " 'that',\n",
       " 'for',\n",
       " 'you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allwords = process(steve_job)\n",
    "allwords# run this to see if the words are words, not letters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "347c0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 4\n",
      "stay 4\n",
      "earth 2\n",
      "catalog 2\n",
      "stewart 2\n",
      "google 2\n",
      "final 2\n",
      "issue 2\n",
      "hungry 2\n",
      "foolish 2\n",
      "young 1\n",
      "amazing 1\n",
      "publication 1\n",
      "called 1\n",
      "bibles 1\n",
      "generation 1\n",
      "created 1\n",
      "fellow 1\n",
      "named 1\n",
      "brand 1\n"
     ]
    }
   ],
   "source": [
    "# write code to count the words, after removing the stop words, \n",
    "# and sort them in descending order, \n",
    "# and then print out the top 20 words\n",
    "countWords = {}\n",
    "\n",
    "def countingWords():\n",
    "    global allwords\n",
    "    global countwords\n",
    "    global stopwords\n",
    "    for word in allwords:\n",
    "        if word not in stopwords and word !='': #checks for blanks and stop words\n",
    "            if word not in countWords: #checks for repeats of word\n",
    "                countWords[word]=1\n",
    "            else:\n",
    "                count = countWords[word]\n",
    "                countWords[word] = count + 1\n",
    "            \n",
    "def sortWords(count):\n",
    "    global countWords\n",
    "    sort = sorted(countWords, key = lambda x: countWords[x],reverse = True)\n",
    "    for i in range(min(len(sort),count)):\n",
    "        word = sort[i]\n",
    "        print(word,countWords[word])\n",
    "                \n",
    "countingWords()\n",
    "sortWords(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d27c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
